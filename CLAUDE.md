# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Common Development Commands

### Development & Build
```bash
npm run dev              # Start dev server on port 3000 with SSL cert warnings bypassed
npm run dev:secure       # Start dev server with TLS enforcement (for OAuth callbacks)
npm run build           # Create production build
npm run lint            # Run ESLint with Next.js & Tailwind rules
```

### Testing
```bash
npx vitest run test/application-qa.test.ts  # Run AI Q&A scoring tests
npx vitest run                               # Run all tests
```

### Production & Workers
```bash
npm run start           # Production server from build artifacts
npm run start:replit    # Replit-specific production server
npm run worker          # Run job processing worker
npm run dev:all         # Run dev server + worker concurrently
```

### Database Migrations
```bash
node scripts/run-migration.js check    # Check current schema status
node scripts/run-migration.js migrate  # Apply missing columns
```

## High-Level Architecture

### AI Document Generation Pipeline
The system uses a multi-model approach with user-configurable preferences:

1. **Model Selection** (`/lib/ai/token-manager.ts`):
   - Primary: User's selected model from settings (Kimi K2 free by default)
   - Free Options: Kimi K2, Grok-4 Fast (2M tokens), Qwen models
   - Paid Options: Grok Code Fast 1 (256K tokens), Claude Sonnet 4, GPT-4o
   - Fallback: Claude Sonnet 4 via OpenRouter on errors only
   - Vision: Qwen2.5-VL-72B for multimodal tasks
   - Settings stored in `user_settings` table and synced to localStorage

2. **Resume Generation** (`/lib/ai/document-generator.ts`):
   - Extracts user data from uploaded resume (NEVER fabricates)
   - Analyzes job description for ATS keywords
   - Creates tailored resume maintaining 100% truthfulness
   - Generates in multiple formats (PDF, DOCX, TXT)

3. **Job Processing** (`/lib/utils/job-processor.ts`):
   - Queue-based async processing with status tracking
   - Handles specific job requests vs queue processing
   - Saves all document formats to Supabase storage

### File Naming Convention
All generated documents follow strict naming:
`{Company}_{LASTNAME}_{JobTitle}_{DocumentType}_{YYYY-MM-DD}_{HHMM}.{ext}`

### Authentication & Session Management
- Supabase Auth with both UUID and session-based user IDs
- Row Level Security (RLS) policies on all user data
- Session persistence across dashboard navigation

### Web Scraping & Data Extraction
- Bright Data MCP for job board scraping (Indeed, LinkedIn, Dice)
- Puppeteer MCP for browser automation
- Jina.ai Reader API for intelligent content extraction

### Document Processing Flow
1. User uploads resume → PDF/DOCX parsing → AI extraction → Store in `resumes` table
2. Job description input → Extract requirements → Store in `job_descriptions` table
3. Generate documents → Save to storage → Track in `generated_resumes` table
4. Download via API routes with proper content types (PDF/DOCX/TXT)

**Important Implementation Details:**
- TXT files are generated by reconstructing content from resume data, NOT by converting PDF
- This ensures TXT matches PDF/DOCX exactly without format artifacts
- See `/app/api/documents/[id]/txt/route.ts` for extraction functions

## Critical Requirements

### Resume Truthfulness (NEVER VIOLATE)
The AI MUST maintain absolute truthfulness when generating documents:
- Use ONLY information from user's uploaded resume
- NEVER invent experiences, skills, or achievements
- NEVER add qualifications the user doesn't have
- Allowed: Reword for ATS, reorganize, use synonyms

### AI Response Handling
When processing AI responses (especially for resume parsing):
- Responses may contain `<think>` tags that must be stripped before JSON parsing
- Markdown code blocks (```json) should be removed
- Extract JSON from first `{` to last `}` if wrapped in other content
- Location: `/app/api/resumeupload/route.ts` - see `extractJSONFromResponse()` function

### Recent Bug Fixes (2025-01-30)
1. **Job Processing**: Fixed inline processor to handle specific job IDs correctly
2. **TXT Generation**: Ensures TXT content matches PDF exactly (via text reconstruction)
3. **DOCX Completeness**: Added missing References section
4. **Certification Display**: Removed "(INACTIVE)" text for expired certs
5. **Clipboard API**: Added fallback for insecure contexts in Q&A component

## Project Structure
```
app/
├── api/               # Next.js API routes
├── dashboard/         # Protected user pages
└── auth/             # Authentication flows

lib/
├── ai/               # AI model integration
├── documents/        # PDF/DOCX/TXT generators
├── supabase/         # Database client & types
└── utils/            # Job processing, helpers

components/
├── ui/               # shadcn primitives
└── [features]/       # Domain components
```

## Environment Variables
Required in `.env.local`:
- `NEXT_PUBLIC_SUPABASE_URL` & `NEXT_PUBLIC_SUPABASE_ANON_KEY`
- `OPENROUTER_API_KEY` for AI models
- `GOOGLE_GENERATIVE_AI_API_KEY` for Gemini
- `BRIGHT_DATA_*` credentials for web scraping
- `JINA_API_KEY` for content extraction

## Testing Strategy
- Unit tests for AI prompt validation in `test/application-qa.test.ts`
- Manual testing of document generation with truthfulness checks
- Verify all formats (PDF, DOCX, TXT) have identical content
- Test job-specific processing with queue disabled

## Code Style Guidelines
From AGENTS.md:
- TypeScript with 2-space indentation
- React components: PascalCase
- Hooks/utilities: camelCase
- Feature folders: kebab-case
- Favor Tailwind utility composition
- Use Conventional Commit prefixes (`feat:`, `fix:`, etc.)